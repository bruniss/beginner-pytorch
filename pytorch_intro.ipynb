{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecdccf2b-b7d1-486e-8643-fb55acf6a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2151d-693e-495b-b461-d65abb9c9f2d",
   "metadata": {},
   "source": [
    "<img src=\"images/tensors_as_sheet.png\" alt=\"Image\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d41b324-2d58-40e9-85d5-87205360bd6f",
   "metadata": {},
   "source": [
    "# Why use Machine Learning?\n",
    "\n",
    "To understand why we might want to use machine learning to solve a given problem, it's important to first understand how this problem would be solved by traditional programming. Take for example, a program designed to look at an image, and output simply whether the photo contains a bird or does not.\n",
    "\n",
    "Finding feature descriptors for even a single bird would prove difficult if not impossible. For a blue jay the following might be a start:\n",
    "\n",
    "- Blue \n",
    "- Feathered\n",
    "- Beak\n",
    "\n",
    "So first you'd have to identify a discrete shape that is blue. Then you'd have to craft something to detect blue jay feathers, and finally something to detect beaks. So lets imagine you've somehow crafted a perfectly reliable blue-jay detection function that when passed a picture of a bluejay can say that it is indeed a bluejay 100% of the time. Consider these problems:\n",
    "\n",
    "- Some other birds are also blue\n",
    "- Blue-jay feathers don't look like goose feathers\n",
    "- If the image is distorted or the lighting is wrong, the parameters for blue and feather-like detectors break\n",
    "- You have to do this all over again for every single bird that exists\n",
    "\n",
    "You can see how the amount of code required to describe and classify whether a photo contains a bird or not could quickly get out of hand. In this case almost certainly impossible to code in a way that works with most images reliably.\n",
    "\n",
    "<img src=\"images/bird_classifier.png\" alt=\"bird\" width=\"200\" height=\"500\">\n",
    "\n",
    "The fundamental difference between machine learning and traditional programming is the following:\n",
    "\n",
    "_In traditional programming you take the input data, and craft a bunch of different rules or operations that will create the desired output_\n",
    "\n",
    "_In machine learning, you take the input data, and the desired output, and the machine learning model creates the rules for you_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f14417-5b4e-4bc4-86ea-89517cc03135",
   "metadata": {},
   "source": [
    "# What is machine learning good at? What is it currently used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0856919d-3df2-4596-b241-858b9ccff0dd",
   "metadata": {},
   "source": [
    "Machine learning excels at problems that have lots of difficult to define rules, think:\n",
    "\n",
    "- Self-Driving vehicles (how many thousands of rules would one have to program to solve this task?)\n",
    "- Environments that are very different in each scenario (like the bird descriptor above)\n",
    "- Problems with huge datasets\n",
    "\n",
    "Currently, deep learning is used in nearly every industry you interact with, just maybe not in ways you've ever considered to be \"AI\" or deep learning. Here are a few examples:\n",
    "\n",
    "- Recommendation algorithms (netflix, youtube, etc)\n",
    "- Language translation (google translate)\n",
    "- Sports broadcasting (player tracking)\n",
    "- Natural language\n",
    "  - Chat GPT\n",
    "  - Spam filters\n",
    "  - Voice activation (\"hey siri\" , \"hey alexa\")\n",
    "- Stock trading\n",
    "- Sports betting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c92293-1c55-454f-9423-23023edf1556",
   "metadata": {},
   "source": [
    "# Some quick definitions\n",
    "\n",
    "These are all examples of machine learning architectures you may have heard of. \n",
    "\n",
    "### Traditional (Shallow)\n",
    "- Examples:\n",
    "  - Random Forest\n",
    "  - Gradient Boosting Machine (XGBoost)\n",
    "  - Bayes\n",
    "  - Nearest Neighbor\n",
    "  - Support Vector Machine\n",
    "- Good for structured data\n",
    "  - Spreadsheets\n",
    "\n",
    "### Deep Learning\n",
    "- Examples:\n",
    "  - Neural Networks (NN)\n",
    "  - Fully Connected Neural Networks (FCCN)\n",
    "  - Convolutional Neural Network (CNN)\n",
    "  - Recurrent Neural Network (RNN)\n",
    "  - Feature Pyramid Network (FPN)\n",
    "  - Transformers\n",
    "- Good for unstructured data\n",
    "  - Language, speech, images, audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6ceaf-5ab9-4946-a680-f69ba82ed542",
   "metadata": {},
   "source": [
    "# What is a neural network? \n",
    "\n",
    "A neural network is a type of program made up of layers of simple units called neurons that are connected together. Each neuron takes in information, processes it, and passes it on to the next layer. By adjusting the connections between neurons, a neural network can learn to recognize patterns in data, like identifying objects in pictures or understanding human speech.\n",
    "\n",
    "### How do neural networks function?\n",
    "\n",
    "- **Inputs and Tensors**:\n",
    "  - A neural network takes inputs, which are numerical data, and organizes them into a matrix (or tensor). Tensors are generalized matrices that can be in multiple dimensions.\n",
    "\n",
    "- **Mathematical Operations and Features**:\n",
    "  - These input tensors undergo a series of mathematical operations, such as matrix multiplications, additions, and the application of activation functions.\n",
    "  - Each layer is usually a combination of linear (straight lines) and non-linear functions.\n",
    "  - Through these operations, the network extracts patterns from the data. These patterns are often referred to as \"features.\"\n",
    "    - Also can be called embedding, feature vectors, weights, etc (not all exactly the same but all terms are used)\n",
    "\n",
    "- **Weights and Representations**:\n",
    "  - The neural network learns these patterns by adjusting \"weights,\" which are the parameters within the model. Each connection between neurons in different layers of the network has an associated weight.\n",
    "  - As the input data passes through the network, these weights are applied to transform the data at each layer, gradually building a more complex representation of the input data.\n",
    "\n",
    "- **Loss Function and Optimization**:\n",
    "  - The network's performance is measured using a loss function, which quantifies the difference between the network's predictions and the actual target values.\n",
    "  - During training, an optimization algorithm (such as gradient descent) adjusts the weights to minimize the loss function. The goal is to find the optimal set of weights that result in the lowest possible loss, indicating that the model is making accurate predictions.\n",
    "\n",
    "<img src=\"images/nn_diagram.png\" alt=\"nn\" width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4060443f-ec5d-46d1-bf69-794fc9aa1145",
   "metadata": {},
   "source": [
    "# What is PyTorch and why should we use it?\n",
    "\n",
    "- Pytorch is the most popular research deep learning framework \n",
    "\n",
    "- Leverages GPUs to run fast deep learning code with python \n",
    "\n",
    "- Access to many prebuilt deep learning models \n",
    "\n",
    "- Manages the entire stack from preprocessing, model creation, training, and deployment \n",
    "\n",
    "- 68% of repositories on paperswithcode.com were written in PyTorch\n",
    "\n",
    "## Why do we do calculations on GPUs? \n",
    "\n",
    "Originally designed for rendering graphics in video games, gpus have thousands of processing cores that are specifically designed to run mathematical calculations extremely quickly. This ability to do math quickly is exactly what we need to quickly train and infer deep learning models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f31640f-f3e4-432a-b6a1-cda46eac3bd1",
   "metadata": {},
   "source": [
    "# A Very brief introduction to vectors and tensors\n",
    "\n",
    "### What is a vector?  \n",
    "\n",
    "A vector is a mathematical object that has both magnitude (length) and direction. \n",
    "\n",
    "Vectors are composed of basis vectors. Basis vectors have a length of 1 in whatever unit of measurement your vector is in (e.g., millimeters, miles per hour) and point in the standard directions of the vector space (e.g., along the x, y, and z axes in 3D space). \n",
    "\n",
    "A vector component is measured by projecting the vector onto the axes. For example, to find the X component, imagine shining a flashlight along the X axis. The shadow of the vector on this axis is the X component. The Y component is the number of basis vectors needed to reach the tip of the vector along the Y axis. \n",
    "\n",
    "In other words, the components are the amounts of the basis vectors required to span from the vector's start to its end along each axis, representing its \"width\" and \"height.\" \n",
    "\n",
    "Once you have the components of a vector, you can represent the vector solely using these components. For instance, a vector $\\mathbf{v}$ in 2D space with components $v_x$ and $v_y$ can be written as:\n",
    "\n",
    "$$\n",
    "\\mathbf{v} = v_x \\mathbf{i} + v_y \\mathbf{j}\n",
    "$$\n",
    "\n",
    "Here, $\\mathbf{i}$ and $\\mathbf{j}$ are the unit vectors along the x and y axes, respectively.\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "### What is a tensor?  \n",
    "\n",
    "Tensors are generalized mathematical objects that can represent vectors, scalars, and more complex structures. \n",
    "\n",
    "| Name   | What is it?                                                                 | Number of dimensions                                                     | Lower or upper (usually/example) |\n",
    "|--------|-----------------------------------------------------------------------------|--------------------------------------------------------------------------|----------------------------------|\n",
    "| scalar | a single number                                                             | 0                                                                        | Lower (a)                        |\n",
    "| vector | a number with direction (e.g., wind speed with direction) but can also have many other numbers | 1                                                                        | Lower (y)                        |\n",
    "| matrix | a 2-dimensional array of numbers                                            | 2                                                                        | Upper (Q)                        |\n",
    "| tensor | an n-dimensional array of numbers                                           | can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector | Upper (X)                        |\n",
    "\n",
    "\n",
    "### What makes tensors so powerful? \n",
    "\n",
    "Different observers might use different ways (basis vectors and components) to describe the same event, but when these ways are combined, everyone agrees on the overall description. This agreement happens because the basis vectors and components change in opposite ways between reference frames, which means the final combined representation remains the same for all observers, regardless of their point of view. \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images/nn_diagram.png\" alt=\"nn\" width=\"550\"></td>\n",
    "        <td><img src=\"images/tensor_examples.png\" alt=\"nn\" width=\"550\"></td>\n",
    "        <td><img src=\"images/vector_components.png\" alt=\"nn\" width=\"550\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09022cdd-4b78-46e4-9693-33492184552c",
   "metadata": {},
   "source": [
    "## Most importantly, tensors can represent _anything_ \n",
    "\n",
    "For example, this tensor could be the sales numbers for a steak and almond butter store. We'll get into the weeds of creating tensors further along, but i wanted to provide these examples to help solidify the use cases for tensors in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3aa39daf-cfe5-4d75-bd55-6d66bd43f0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [3, 6, 9],\n",
      "         [2, 4, 5]]])\n",
      "torch.Size([1, 3, 3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor([[[1, 2, 3],\n",
    "                      [3, 6, 9],\n",
    "                      [2, 4, 5]]])\n",
    "print(data)\n",
    "print(data.shape)\n",
    "print(data.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467b48ae-3536-4ed4-98d9-d2612cf40c15",
   "metadata": {},
   "source": [
    "<img src=\"images/tensor_sheet.png\" alt=\"nn\" width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53023255-3dc5-4013-a2a4-8ece9af4b724",
   "metadata": {},
   "source": [
    "This tensor could represent an RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e988f247-84d0-45d8-b1a7-d4416e388363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2432, 0.7010, 0.7721,  ..., 0.2164, 0.6718, 0.1104],\n",
      "         [0.3590, 0.1136, 0.6191,  ..., 0.3251, 0.9227, 0.7909],\n",
      "         [0.9908, 0.5999, 0.8407,  ..., 0.0043, 0.3359, 0.9595],\n",
      "         ...,\n",
      "         [0.2602, 0.8757, 0.0726,  ..., 0.6321, 0.2288, 0.7053],\n",
      "         [0.0192, 0.9383, 0.8483,  ..., 0.6931, 0.0705, 0.4954],\n",
      "         [0.7864, 0.0267, 0.7485,  ..., 0.6296, 0.4062, 0.9518]],\n",
      "\n",
      "        [[0.2406, 0.5715, 0.8695,  ..., 0.5303, 0.6114, 0.5407],\n",
      "         [0.9878, 0.0021, 0.0584,  ..., 0.3154, 0.8661, 0.7833],\n",
      "         [0.3563, 0.2200, 0.3609,  ..., 0.9002, 0.4999, 0.9957],\n",
      "         ...,\n",
      "         [0.0317, 0.1195, 0.1462,  ..., 0.3885, 0.0491, 0.9648],\n",
      "         [0.1645, 0.2449, 0.9733,  ..., 0.5273, 0.4287, 0.5294],\n",
      "         [0.4534, 0.3744, 0.7875,  ..., 0.6244, 0.4987, 0.9975]],\n",
      "\n",
      "        [[0.0131, 0.8527, 0.5348,  ..., 0.3034, 0.4661, 0.0858],\n",
      "         [0.4131, 0.1749, 0.3724,  ..., 0.4518, 0.4753, 0.3724],\n",
      "         [0.7175, 0.4745, 0.8599,  ..., 0.8641, 0.8318, 0.1138],\n",
      "         ...,\n",
      "         [0.7994, 0.0176, 0.5381,  ..., 0.0117, 0.2281, 0.1198],\n",
      "         [0.6120, 0.9408, 0.9678,  ..., 0.7928, 0.0736, 0.6712],\n",
      "         [0.7746, 0.6783, 0.0505,  ..., 0.0995, 0.1519, 0.9814]]])\n",
      "torch.Size([3, 224, 224])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "image = torch.rand(3, 224, 224)\n",
    "print(image)\n",
    "print(image.shape)\n",
    "print(image.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590fff7f-c5a1-4ecb-9e24-39d3f41b4bef",
   "metadata": {},
   "source": [
    "<img src=\"images/image_as_tensor.png\" alt=\"nn\" width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa09ef-2a26-4958-84c1-d5ed60ec4afe",
   "metadata": {},
   "source": [
    "# ok lets create some tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce858a5-6c2b-4edb-bf64-e8d3e6e7456d",
   "metadata": {},
   "source": [
    "### Creating a scalar (or a 0D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af1a9ec1-6e20-4c99-bf69-375926cf0f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "scalar shape: torch.Size([]) scalar ndim 0\n"
     ]
    }
   ],
   "source": [
    "# a scalar is a single numbered tensor\n",
    "\n",
    "scalar = torch.tensor(5)\n",
    "print(scalar)\n",
    "print(f\"scalar shape: {scalar.shape} scalar ndim {scalar.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e7a35-0a82-4f94-8547-3d2a50526891",
   "metadata": {},
   "source": [
    "> A scalar is the simplest form of a tensor. It is a single number and does not have any dimensions. In other words, a scalar has zero axes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a262c9a4-ad4b-4792-ae50-88be16997695",
   "metadata": {},
   "source": [
    "### Creating a vector (or a 1D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ddce4da-445f-4ee1-87bd-432c1b87fdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "vector_one shape: torch.Size([2]) vector_one ndim 1\n",
      "tensor([ 1,  5,  8, 15, 25])\n",
      "vector_two shape: torch.Size([5]) vector_two ndim 1\n"
     ]
    }
   ],
   "source": [
    "# a vector is a single dimensioned tensors of an arbitrary amount of numbers\n",
    "vector_one = torch.tensor([1, 2])\n",
    "vector_two = torch.tensor([1, 5, 8, 15, 25])\n",
    "\n",
    "print(vector_one)\n",
    "print(f\"vector_one shape: {vector_one.shape} vector_one ndim {vector_one.ndim}\")\n",
    "print(vector_two)\n",
    "print(f\"vector_two shape: {vector_two.shape} vector_two ndim {vector_two.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d205d-44f8-42f4-bc94-ec3151a93d76",
   "metadata": {},
   "source": [
    "**Dimensionality**\n",
    "\n",
    "> Notice how the number of dimensions for both vectors remain the same, even if their contents vary in length or values. The \"dimensionality\" of a tensor refers to the number of axes it has. For example, a 2D tensor (or matrix) has two dimensions: rows and columns. In this case our tensor contains only rows, making it a 1D tensor. Vectors are always 1D tensors, since they always contain only rows.\n",
    ">\n",
    "> An easy trick to tell the number of dimensions a tensor in PyTorch is to count the number of square brackets on the outside ([), counting only one side. Our vector example only has one (just to the left of the 1).\n",
    "\n",
    "**Shape**\n",
    "\n",
    "> We also print out the 'shape' of our tensor with\n",
    "> \n",
    "```python\n",
    " \n",
    " print(vector_one.shape)\n",
    " \n",
    "```\n",
    "> \n",
    "> The 'shape' of a tensor describes the dimensions of the tensor. For a 1D tensor (vector), the shape is represented by a single value, which is the number of elements in the vector. We can print out the shape of our tensor using the shape attribute.\n",
    "> \n",
    "> For example, if we have a vector with 5 elements, its shape will be (5,), indicating that it has 5 elements in one dimension.\n",
    "> To get the shape of a tensor manually, you would count the number of elements in the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34aa08-884e-4141-a922-9dfc3132e414",
   "metadata": {},
   "source": [
    "### Creating a matrix (or a 2D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a1deb27-dcb8-41f0-8e58-cab1bd4beb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n",
      "matrix shape: torch.Size([2, 2]) matrix ndim 2\n"
     ]
    }
   ],
   "source": [
    "# a matrix is a two-dimensional tensor consisting of rows and columns\n",
    "\n",
    "matrix = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "print(matrix)\n",
    "print(f\"matrix shape: {matrix.shape} matrix ndim {matrix.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb8f53-4766-46d8-a229-3195d8dd87db",
   "metadata": {},
   "source": [
    "> **Note:** In this example, our matrix has 2 rows and 2 columns. This is reflected in its shape, which is (2, 2). The first number in the shape tuple represents the number of rows, and the second number represents the number of columns. Since we have both rows and columns, our matrix is two-dimensional. If we added more rows or columns, the shape would change accordingly, but it would still be a two-dimensional tensor because it has both rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee7fac5-c4a9-4e62-bcf5-e07483fc6e22",
   "metadata": {},
   "source": [
    "### Creating a tensor \n",
    "\n",
    ">**Note**: Tensors are considered \"n dimensional\" (sometimes written as nD), meaning they can have any number of dimensions. In this instance we'll just create a simple 3 dimensional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edb26a0f-5dba-4041-91c7-ff32ea90b96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 5],\n",
      "         [3, 4, 6],\n",
      "         [7, 8, 9]]])\n",
      "tensor_3d shape: torch.Size([1, 3, 3]), tensor_3d ndim: 3\n"
     ]
    }
   ],
   "source": [
    "# 3D Tensor\n",
    "tensor_3d = torch.tensor([[[1, 2, 5], \n",
    "                           [3, 4, 6], \n",
    "                           [7, 8, 9]]])\n",
    "print(tensor_3d)\n",
    "print(f\"tensor_3d shape: {tensor_3d.shape}, tensor_3d ndim: {tensor_3d.ndim}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057c07e-5b75-4999-b47a-7be19b2533e3",
   "metadata": {},
   "source": [
    "> **Note:** In this example, our 3D tensor has 1 layer, each with 3 rows and 3 columns. This is reflected in its shape, which is (1, 3, 3). The first number represents the number of layers (if this tensor had two layers, it would be (2, 3, 3), imagine another tensor \"stacked on top of it\"), the second number represents the number of rows, and the third number represents the number of columns. Since we have a single layer of rows and columns, our tensor is three-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab1475-2db8-4d2a-aca5-fc83cae7541b",
   "metadata": {},
   "source": [
    "## Random tensors\n",
    "We've now created some basic tensors, established that tensors represent some form of data, and learned how machine learning models such as neural networks manipulate and seek patterns within tensors.\n",
    "\n",
    "But when building machine learning models with PyTorch, it's rare you'll create tensors by hand (like what we've being doing).\n",
    "\n",
    "Instead, a machine learning model often starts out with large random tensors of numbers and adjusts these random numbers as it works through data to better represent it.\n",
    "\n",
    "In essence:\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`\n",
    "\n",
    "As a data scientist, you can define how the machine learning model starts (initialization), looks at data (representation) and updates (optimization) its random numbers.\n",
    "\n",
    "We'll get hands on with these steps later on.\n",
    "\n",
    "For now, let's see how to create a tensor of random numbers.\n",
    "\n",
    "We can do so using torch.rand() and passing in the size parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffc9bd53-9bc7-4ba1-86a3-bebd56511664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4609, 0.7994, 0.5346, 0.8761],\n",
      "        [0.4840, 0.5521, 0.6118, 0.0815],\n",
      "        [0.9449, 0.1316, 0.6658, 0.0100]])\n",
      "random_tensor shape: torch.Size([3, 4]) random_tensor ndim 2\n"
     ]
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "print(random_tensor)\n",
    "print(f\"random_tensor shape: {random_tensor.shape} random_tensor ndim {random_tensor.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c930761c-9e7a-4e2b-aa75-be43fb4ec627",
   "metadata": {},
   "source": [
    "## Tensors filled with zeros or ones\n",
    "\n",
    "Often you'll use a tensor filled with either zeroes or ones to mark where a model should or should not look for features. PyTorch thankfully has two simple methods for accomplishing this task as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba8ae2fe-effc-47c9-bd39-867344f38a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "zeros shape: torch.Size([3, 4]) zeros ndim 2\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "print(zeros)\n",
    "print(f\"zeros shape: {zeros.shape} zeros ndim {zeros.ndim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60a235ee-d66e-43ea-a678-54f8d76e6b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "ones shape: torch.Size([3, 4]) ones ndim 2\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "print(ones)\n",
    "print(f\"ones shape: {ones.shape} ones ndim {ones.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c0bfd9-0adf-4da7-860f-11515c9d6f66",
   "metadata": {},
   "source": [
    "## Creating tensors with the same shape and type as another tensor\n",
    "\n",
    "For example, a tensor of all zeros with the same shape as a previous tensor.\n",
    "\n",
    "To do so you can use `torch.zeros_like(input)` or `torch.ones_like(input)` which return a tensor filled with zeros or ones in the same shape as the input respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f7460b6-28cd-43fe-b984-daf86789ffe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_tensor shape: torch.Size([3, 4]) s_tensor ndim 2\n",
      "tensor([[0.1160, 0.2033, 0.4449, 0.9072],\n",
      "        [0.9191, 0.9119, 0.5404, 0.5092],\n",
      "        [0.5843, 0.7298, 0.2457, 0.6130]])\n",
      "s_zeros shape: torch.Size([3, 4]) s_zeros ndim 2\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# we'll create a 2 dimensional tensor of size (3, 4) filled with random numbers, and then create a tensor of the same shape and dimensionality\n",
    "# but filled with zeros\n",
    "\n",
    "s_tensor = torch.rand(3, 4)\n",
    "s2_tensor = s_tensor #copying s_tensor so i can print its original values\n",
    "s_zeros = torch.zeros_like(input=s2_tensor) # will have same shape\n",
    "\n",
    "print(f\"s_tensor shape: {s_tensor.shape} s_tensor ndim {s_tensor.ndim}\")\n",
    "print(s_tensor)\n",
    "\n",
    "print(f\"s_zeros shape: {s_zeros.shape} s_zeros ndim {s_zeros.ndim}\")\n",
    "print(s_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fde305-546e-44e8-8c69-db38cef65cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
